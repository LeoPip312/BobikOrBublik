{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e036d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd32865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_cat_model():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, (3, 3), input_shape=(128, 128, 3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(units=128, activation='relu'))\n",
    "  model.add(Dense(units=1, activation='sigmoid'))\n",
    "  model.compile(optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9edd08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_cat_train(model):\n",
    "  # splits = tfds.Split.TRAIN.subsplit(weighted=(80, 10, 10))\n",
    "  (cat_train, cat_valid, cat_test), info = tfds.load('cats_vs_dogs', split='train[:75%]', with_info=True, as_supervised=True)\n",
    "\n",
    "  def pre_process_image(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255.0\n",
    "    image = tf.image.resize(image, (128, 128))\n",
    "    return image, label\n",
    "\n",
    "  BATCH_SIZE = 32\n",
    "  SHUFFLE_BUFFER_SIZE = 1000\n",
    "  train_batch = cat_train.map(pre_process_image).shuffle(SHUFFLE_BUFFER_SIZE).repeat().batch(BATCH_SIZE)\n",
    "  validation_batch = cat_valid.map(pre_process_image).repeat().batch(BATCH_SIZE)\n",
    "\n",
    "  t_start = time.time()\n",
    "  model.fit(train_batch, steps_per_epoch=4000, epochs=2,\n",
    "    validation_data=validation_batch,\n",
    "    validation_steps=10,\n",
    "    callbacks=None)\n",
    "  print(\"Training done, dT:\", time.time() - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4e57f71",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_datasets' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m dog_cat_model()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdog_cat_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdogs_cats.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m, in \u001b[0;36mdog_cat_train\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdog_cat_train\u001b[39m(model):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;66;03m# splits = tfds.Split.TRAIN.subsplit(weighted=(80, 10, 10))\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m   (cat_train, cat_valid, cat_test), info \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcats_vs_dogs\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain[:75\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, with_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, as_supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpre_process_image\u001b[39m(image, label):\n\u001b[0;32m      6\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(image, tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_datasets' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "model = dog_cat_model()\n",
    "dog_cat_train(model)\n",
    "model.save('dogs_cats.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c9f4c98-b3f4-451d-aae4-a89aefd11a05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79c0596c-851d-4370-a590-eeca5b0da037",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7dd7cb-52a1-4260-8fbf-4fb5ddad1ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31055059-4c2b-4e2c-b853-5c40b651df6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997307f-c88f-4f84-9d89-29b7ef912382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
